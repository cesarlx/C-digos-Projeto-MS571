{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Yq6Wt5taSTy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import holidays\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "IePNv7-0aXs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================\n",
        "# Configurações e dados\n",
        "# ===========================================\n",
        "SEED = 42\n",
        "br_holidays = holidays.Brazil(years=[2024, 2025])\n",
        "sp_holidays = holidays.Brazil(years=[2024, 2025], prov='SP')"
      ],
      "metadata": {
        "id": "D0x3tIsVaUZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghjZhblGm2A6",
        "outputId": "f60e6a7d-4ca9-44ee-9eb1-44b0078a148a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carrega dataset\n",
        "df_transformada = pd.read_csv(\"dados_transformados.csv\")\n",
        "#df_transformada = pd.read_csv(\"cardapio_final (1).csv\")\n",
        "df_transformada[\"Data\"] = pd.to_datetime(df_transformada[\"Data\"])"
      ],
      "metadata": {
        "id": "UuPHZR-uaZE6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "d498adae-e64c-4a15-df8f-db83a092c53a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'dados_transformados.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3367075152.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Carrega dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_transformada\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dados_transformados.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#df_transformada = pd.read_csv(\"cardapio_final (1).csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_transformada\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_transformada\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dados_transformados.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_transformada.head()"
      ],
      "metadata": {
        "id": "Wbce9QUfYGSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_categorizada = pd.read_csv(\"cardapio_final.csv\")\n",
        "df_categorizada[\"Data\"] = pd.to_datetime(df_transformada[\"Data\"])\n",
        "df_categorizada.head()"
      ],
      "metadata": {
        "id": "kU5pvwkWd2MF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_transformada.merge(\n",
        "    df_categorizada[[\"Data\", \"cardapio_trans\", \"Ferias\"]],\n",
        "    on=\"Data\",\n",
        "    how=\"left\"\n",
        ")"
      ],
      "metadata": {
        "id": "vCdpGDzweZ0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================\n",
        "# Feature Engineering\n",
        "# ===========================================\n",
        "# Codificação categórica\n",
        "categorical_cols = [\"refeicao\", \"Dia_Semana\", \"cardapio_trans\", \"Ferias\"]\n",
        "le_dict = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col].astype(str))\n",
        "\n",
        "    le_dict[col] = le\n",
        "\n",
        "# Features de tempo\n",
        "df[\"is_weekend\"] = (df[\"Data\"].dt.weekday >= 5).astype(int)\n",
        "\n",
        "sp_holidays_ts = [pd.Timestamp(f) for f in sp_holidays]\n",
        "df[\"feriado\"] = df[\"Data\"].isin(sp_holidays_ts).astype(int)\n",
        "\n",
        "def holiday_week(x):\n",
        "    start_week = x - pd.Timedelta(days=x.weekday())  # segunda\n",
        "    end_week = start_week + pd.Timedelta(days=6)     # domingo\n",
        "    return int(any(start_week <= f <= end_week for f in sp_holidays_ts))\n",
        "\n",
        "df[\"is_holiday_week\"] = df[\"Data\"].apply(holiday_week)\n",
        "df[\"days_to_holiday\"] = df[\"Data\"].apply(\n",
        "    lambda x: min(abs((x - f).days) for f in sp_holidays_ts)\n",
        ")\n",
        "\n",
        "# Lags e médias móveis\n",
        "df[\"lag_1\"] = df[\"total_refeicao\"].shift(1)\n",
        "df[\"lag_7\"] = df[\"total_refeicao\"].shift(7)\n",
        "# df[\"rolling_3\"] = df[\"total_refeicao\"].rolling(3).mean()\n",
        "# df[\"rolling_7\"] = df[\"total_refeicao\"].rolling(7).mean()\n",
        "# df[\"rolling_3_mod\"] = df[\"rolling_3\"] + np.random.normal(\n",
        "#     0, 0.1 * df[\"rolling_3\"].std(), len(df)\n",
        "# )\n",
        "\n",
        "# Remove linhas com NaN (de lags)\n",
        "df = df.dropna()\n",
        "\n",
        "# Features adicionais\n",
        "df[\"mes\"] = df[\"Data\"].dt.month\n",
        "df[\"semana_ano\"] = df[\"Data\"].dt.isocalendar().week.astype(int)"
      ],
      "metadata": {
        "id": "RD_Er_8aaimm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelagem"
      ],
      "metadata": {
        "id": "G5IkRYn8bvwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================\n",
        "# Divisão treino / teste\n",
        "# ===========================================\n",
        "split_date = '2025-04-30'\n",
        "train_df = df[df[\"Data\"] <= split_date]\n",
        "test_df = df[df[\"Data\"] > split_date]\n",
        "\n",
        "# features = [\n",
        "#     \"refeicao\", \"cardapio_padrao\", \"Dia_Semana\",\n",
        "#     \"precip\", \"tavg\", \"tmin\", \"tmax\",\n",
        "#     \"is_weekend\", \"feriado\", \"is_holiday_week\",\n",
        "#     \"lag_1\", \"lag_7\", \"rolling_3\", \"rolling_7\",\n",
        "#     \"mes\", \"semana_ano\", \"days_to_holiday\"\n",
        "# ]\n",
        "\n",
        "features = [\n",
        "    \"refeicao\", \"Dia_Semana\", \"tavg\",\n",
        "    \"is_weekend\", \"feriado\", \"is_holiday_week\",\n",
        "    \"lag_1\", \"lag_7\",\n",
        "    \"mes\", \"semana_ano\", \"days_to_holiday\", \"cardapio_trans\", \"Ferias\"\n",
        "]\n",
        "target = \"total_refeicao\""
      ],
      "metadata": {
        "id": "d3QoD-TBcd1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get_dummies garante compatibilidade\n",
        "X_train = pd.get_dummies(train_df[features], columns=categorical_cols, drop_first=True)\n",
        "X_test = pd.get_dummies(test_df[features], columns=categorical_cols, drop_first=True)\n",
        "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)"
      ],
      "metadata": {
        "id": "OtfGfVULccOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train_df[target]\n",
        "y_test = test_df[target]"
      ],
      "metadata": {
        "id": "hF26NpgjcwrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================\n",
        "# Treinamento com RandomForest + GridSearch\n",
        "# ===========================================\n",
        "# param_grid = {\n",
        "#     \"n_estimators\": [200, 400, 800],\n",
        "#     \"max_depth\": [None, 10, 20],\n",
        "#     \"min_samples_split\": [2, 5, 10],\n",
        "#     \"min_samples_leaf\": [1, 2, 4]\n",
        "# }\n",
        "#\n",
        "# grid = GridSearchCV(\n",
        "#     RandomForestRegressor(random_state=SEED),\n",
        "#     param_grid,\n",
        "#     cv=3,\n",
        "#     scoring=\"r2\",\n",
        "#     n_jobs=-1\n",
        "# )\n",
        "#\n",
        "# grid.fit(X_train, y_train)\n",
        "# print(\"Melhores parâmetros:\", grid.best_params_)\n",
        "#\n",
        "# best_rf = grid.best_estimator_"
      ],
      "metadata": {
        "id": "aQe7rj1wkXRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = RandomForestRegressor(random_state=SEED, n_estimators=300, max_depth=12, min_samples_split=2, min_samples_leaf=1)\n",
        "model = RandomForestRegressor(random_state=SEED, n_estimators=400, max_depth=None, min_samples_split=2, min_samples_leaf=2)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "zRpiU_X4PXUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================\n",
        "# Avaliação do modelo\n",
        "# ===========================================\n",
        "#y_pred = best_rf.predict(X_test)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred) * 100\n",
        "\n",
        "print(f\"\\n--- Random Forest ---\")\n",
        "print(f\"MAE: {mae:.2f} alunos\")\n",
        "print(f\"RMSE: {rmse:.2f} alunos\")\n",
        "print(f\"R²: {r2:.3f}\")\n",
        "\n",
        "feat_names = X_train.columns\n",
        "importances = model.feature_importances_\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    \"feature\": feat_names,\n",
        "    \"importance\": importances\n",
        "}).sort_values(by=\"importance\", ascending=False)\n",
        "print(\"\\n\")\n",
        "print(feature_importance)"
      ],
      "metadata": {
        "id": "wMomvSApcyTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste alternativo com HistGradientBoosting\n",
        "hgb = HistGradientBoostingRegressor(random_state=SEED)\n",
        "hgb.fit(X_train, y_train)\n",
        "y_pred_hgb = hgb.predict(X_test)\n",
        "\n",
        "mae_hgb = mean_absolute_error(y_test, y_pred_hgb)\n",
        "rmse_hgb = np.sqrt(mean_squared_error(y_test, y_pred_hgb))\n",
        "r2_hgb = r2_score(y_test, y_pred_hgb) * 100\n",
        "\n",
        "print(f\"\\n--- HistGradientBoosting ---\")\n",
        "print(f\"MAE: {mae_hgb:.2f} alunos\")\n",
        "print(f\"RMSE: {rmse_hgb:.2f} alunos\")\n",
        "print(f\"R²: {r2_hgb:.3f}\")"
      ],
      "metadata": {
        "id": "ekUnythSc8KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização\n",
        "resultados = test_df[[\"Data\"]].copy()\n",
        "resultados[\"Real\"] = y_test.values\n",
        "resultados[\"Previsto_RF\"] = y_pred\n",
        "resultados[\"Previsto_HGB\"] = y_pred_hgb\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(resultados[\"Data\"], resultados[\"Real\"], label=\"Real\", linewidth=2)\n",
        "plt.plot(resultados[\"Data\"], resultados[\"Previsto_RF\"], \"--\", label=\"Random Forest\")\n",
        "plt.plot(resultados[\"Data\"], resultados[\"Previsto_HGB\"], \":\", label=\"HistGradientBoosting\")\n",
        "plt.title(\"Previsão de Demanda de Refeições\", fontsize=14)\n",
        "plt.xlabel(\"Data\")\n",
        "plt.ylabel(\"Total de Refeições\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "D3s0PGohjnLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Métodos de Aprendizado não supervisionado"
      ],
      "metadata": {
        "id": "OwFT0_3gkhj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# K-means\n",
        "print(df.columns.tolist())\n",
        "\n",
        "cols = ['Dia_Semana', 'cardapio_trans', 'refeicao',\n",
        "        'Ferias', 'feriado', 'is_holiday_week',\n",
        "        'tavg', 'precip']\n",
        "\n",
        "# one-hot sem drop_first\n",
        "X = pd.get_dummies(df[cols], drop_first=False)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Aplico o método do cotovelo\n",
        "\n",
        "inertias = []\n",
        "K = range(2, 12)\n",
        "\n",
        "for k in K:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertias.append(kmeans.inertia_)\n",
        "\n",
        "# Usamos o Silhouette Score para avaliar\n",
        "sil_scores = []\n",
        "\n",
        "for k in K:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    labels = kmeans.fit_predict(X_scaled)\n",
        "    sil = silhouette_score(X_scaled, labels)\n",
        "    sil_scores.append(sil)\n",
        "\n",
        "for k, sil in zip(K, sil_scores):\n",
        "    print(f\"k={k} → Silhouette={sil:.4f}\")"
      ],
      "metadata": {
        "id": "Jh5ZfO_kkb7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testar modelo para predição"
      ],
      "metadata": {
        "id": "A1uselRSQmCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prever_consumo(model, df, le_dict, X_train, data_prevista,\n",
        "                   refeicao, cardapio_trans, tavg):\n",
        "\n",
        "    # Monta linha base\n",
        "    new = pd.DataFrame({\"Data\": [pd.to_datetime(data_prevista)]})\n",
        "\n",
        "    # Converte dias da semana para PT igual ao treino\n",
        "    dias_pt = {\n",
        "        0: \"Segunda\",\n",
        "        1: \"Terça\",\n",
        "        2: \"Quarta\",\n",
        "        3: \"Quinta\",\n",
        "        4: \"Sexta\",\n",
        "        5: \"Sábado\",\n",
        "        6: \"Domingo\"\n",
        "    }\n",
        "    dia_idx = new[\"Data\"].dt.weekday.iloc[0]\n",
        "    dia_semana = dias_pt[dia_idx]\n",
        "\n",
        "    # Label encoding com fallback para categorias novas\n",
        "    def safe_transform(col, value):\n",
        "        if value in le_dict[col].classes_:\n",
        "            return le_dict[col].transform([value])[0]\n",
        "        print(f\"Aviso: nova categoria '{value}' em '{col}'. Definindo como 0.\")\n",
        "        return 0\n",
        "\n",
        "    new[\"refeicao\"] = safe_transform(\"refeicao\", refeicao)\n",
        "    new[\"cardapio_trans\"] = safe_transform(\"cardapio_trans\", cardapio_trans)\n",
        "    new[\"Dia_Semana\"] = safe_transform(\"Dia_Semana\", dia_semana)\n",
        "\n",
        "    # Clima\n",
        "    new[\"tavg\"] = tavg\n",
        "\n",
        "    # Feriados\n",
        "    sp_holidays_ts = [pd.Timestamp(f) for f in sp_holidays]\n",
        "    data = new[\"Data\"].iloc[0]\n",
        "\n",
        "    new[\"is_weekend\"] = int(dia_idx >= 5)\n",
        "    new[\"feriado\"] = int(data in sp_holidays_ts)\n",
        "\n",
        "    def holiday_week(x):\n",
        "        start = x - pd.Timedelta(days=x.weekday())\n",
        "        end = start + pd.Timedelta(days=6)\n",
        "        return int(any(start <= f <= end for f in sp_holidays_ts))\n",
        "\n",
        "    new[\"is_holiday_week\"] = holiday_week(data)\n",
        "    new[\"days_to_holiday\"] = min(abs((data - f).days) for f in sp_holidays_ts)\n",
        "\n",
        "    # Tempo\n",
        "    new[\"mes\"] = new[\"Data\"].dt.month\n",
        "    new[\"semana_ano\"] = new[\"Data\"].dt.isocalendar().week.astype(int)\n",
        "\n",
        "    # Lags e médias móveis baseadas no dataset mais recente\n",
        "    ultima_data = df[\"Data\"].max()\n",
        "\n",
        "    new[\"lag_1\"] = df.loc[df[\"Data\"] == ultima_data, \"total_refeicao\"].values[0]\n",
        "\n",
        "    data_7 = ultima_data - pd.Timedelta(days=7)\n",
        "    new[\"lag_7\"] = df.loc[df[\"Data\"] == data_7, \"total_refeicao\"].values[0] if (df[\"Data\"] == data_7).any() else new[\"lag_1\"]\n",
        "\n",
        "    # new[\"rolling_3\"] = df[\"total_refeicao\"].tail(3).mean()\n",
        "    # new[\"rolling_7\"] = df[\"total_refeicao\"].tail(7).mean()\n",
        "\n",
        "    # Prepara entrada p/ modelo\n",
        "    new_X = new.drop(columns=[\"Data\"])\n",
        "    new_X = pd.get_dummies(new_X, columns=[\"refeicao\", \"cardapio_trans\", \"Dia_Semana\"], drop_first=True)\n",
        "    new_X = new_X.reindex(columns=X_train.columns, fill_value=0)\n",
        "\n",
        "    # Predição\n",
        "    pred = model.predict(new_X)[0]\n",
        "    return round(pred, 2)\n"
      ],
      "metadata": {
        "id": "quitaGLwUXie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsao = prever_consumo(\n",
        "    model=model,\n",
        "    df=df,\n",
        "    le_dict=le_dict,\n",
        "    X_train=X_train,\n",
        "    data_prevista=\"2025-10-30\",\n",
        "    refeicao=\"Almoço\",\n",
        "    cardapio_trans=\"frango\",\n",
        "    tavg=20,\n",
        ")\n",
        "\n",
        "print(\"Previsão de alunos:\", previsao)"
      ],
      "metadata": {
        "id": "wX3D8hVeUlgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsao = prever_consumo(\n",
        "    model=model_weighted,\n",
        "    df=df,\n",
        "    le_dict=le_dict,\n",
        "    X_train=X_train,\n",
        "    data_prevista=\"2025-10-30\",\n",
        "    refeicao=\"Almoço\",\n",
        "    cardapio_trans=\"carne bovina\",\n",
        "    tavg=20,\n",
        ")\n",
        "\n",
        "print(\"Previsão de alunos:\", previsao)"
      ],
      "metadata": {
        "id": "4B2X7TDic_Tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsao = prever_consumo(\n",
        "    model=model_weighted,\n",
        "    df=df,\n",
        "    le_dict=le_dict,\n",
        "    X_train=X_train,\n",
        "    data_prevista=\"2025-10-30\",\n",
        "    refeicao=\"Jantar\",\n",
        "    cardapio_trans=\"frango\",\n",
        "    tavg=20,\n",
        ")\n",
        "\n",
        "print(\"Previsão de alunos:\", previsao)"
      ],
      "metadata": {
        "id": "bedbK9DBdFCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsao = prever_consumo(\n",
        "    model=hgb,\n",
        "    df=df,\n",
        "    le_dict=le_dict,\n",
        "    X_train=X_train,\n",
        "    data_prevista=\"2025-10-30\",\n",
        "    refeicao=\"Almoço\",\n",
        "    cardapio_trans=\"frango\",\n",
        "    tavg=20,\n",
        ")\n",
        "\n",
        "print(\"Previsão de alunos:\", previsao)"
      ],
      "metadata": {
        "id": "7UFkNLHHdQ-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IHbUl-3udOPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "N0etbnFOg5p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat_names = X_train.columns\n",
        "importances = model.feature_importances_\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    \"feature\": feat_names,\n",
        "    \"importance\": importances\n",
        "}).sort_values(by=\"importance\", ascending=False)\n",
        "\n",
        "print(feature_importance)\n"
      ],
      "metadata": {
        "id": "VaCQssLWxKiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat_names = X_train.columns\n",
        "importances = model_weighted.feature_importances_\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    \"feature\": feat_names,\n",
        "    \"importance\": importances\n",
        "}).sort_values(by=\"importance\", ascending=False)\n",
        "\n",
        "print(feature_importance)\n"
      ],
      "metadata": {
        "id": "ANuQu12ldAdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CGZo98B6zu9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n"
      ],
      "metadata": {
        "id": "bjOsTZslbK7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pega uma árvore do Random Forest\n",
        "estimator = model.estimators_[0]\n",
        "\n",
        "dot_data = export_graphviz(\n",
        "    estimator,\n",
        "    out_file=None,\n",
        "    feature_names=X_train.columns,\n",
        "    filled=True,\n",
        "    rounded=True,\n",
        "    special_characters=True\n",
        ")\n",
        "\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"arvore_random_forest\")  # salva como PDF\n",
        "graph\n"
      ],
      "metadata": {
        "id": "j4TMZ_B8bLCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mzn2_zLabMpS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}